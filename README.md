# ü¶ô Mistral 7B Local Server (con FastAPI y llama.cpp)

Este proyecto expone un asistente ligero mediante `fastapi` y `llama.cpp`.  
Para mantener el repositorio limpio no se incluye el entorno virtual ni los binarios
que genera. Al clonar simplemente recrea el entorno usando `requirements.txt`.

## üöÄ C√≥mo iniciar

```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
./start.sh
```

Puedes personalizar la ruta del modelo, el puerto, los or√≠genes permitidos y el archivo de reglas exportando las
variables de entorno `MODEL_PATH`, `PORT`, `ALLOWED_ORIGINS` y `RULES_FILE` antes de arrancar:

```bash
export MODEL_PATH=/ruta/al/modelo.gguf
export PORT=9000
export RULES_FILE=/ruta/a/mis_reglas.txt
export ALLOWED_ORIGINS=http://localhost:3000
./start.sh
```
Puedes indicar varios or√≠genes separ√°ndolos con comas.

## üß™ C√≥mo probar

Desde consola del navegador:

```js
fetch("http://localhost:8000/api/chat", {
  method: "POST",
  headers: { "Content-Type": "application/json" },
  body: JSON.stringify({ prompt: "¬øQu√© es una LLC?" })
}).then(res => res.json()).then(console.log);
```

Modelo usado: `mistral-7b-instruct-v0.1.Q4_K_M.gguf`

## ‚úÖ Ejecutar pruebas

Para correr las pruebas unitarias usa `pytest`:

```bash
pytest
```
## üìÑ Licencia

Este proyecto est√° bajo la [Licencia MIT](LICENSE).

## üê≥ Docker

Para construir la imagen ejecuta:

```bash
docker build -t fennec-back .
```

Y para iniciar el contenedor mapea el puerto 8000:

```bash
docker run -p 8000:8000 fennec-back
```
## Abrir la interfaz

Con el servidor en marcha abre `fennec_assistant.html` en tu navegador.
Por defecto busca la API en `http://localhost:8000`, por lo que si cambiaste
el puerto aseg√∫rate de modificar la URL en el c√≥digo o ajustar la variable
`PORT` antes de abrir el archivo.

Adem√°s se incluye la p√°gina `index.html` que muestra un asistente por pasos.
Su l√≥gica se encuentra en `script.js` y la estructura de datos en
`data/stepsData.json`, los cuales se cargan de forma externa cuando se abre
la p√°gina. Mant√©n estos archivos en el mismo directorio para que el navegador
pueda localizarlos sin problemas.

Para evitar errores al cargar los archivos JSON, ejecuta `index.html` con el
script `serve_index.py`. Esta utilidad inicia un servidor HTTP sencillo y abre
la p√°gina autom√°ticamente:

```bash
python3 serve_index.py
```

Puedes cambiar el puerto estableciendo la variable `PORT` antes de ejecutarlo.

Si utilizas macOS y prefieres contar con una aplicaci√≥n `.app`, puedes generar
una con `pyinstaller`:

```bash
pip install pyinstaller
pyinstaller --onefile --windowed serve_index.py
```

El paquete resultante se ubicar√° en `dist/` y podr√°s lanzarlo con doble clic.

## üõ†Ô∏è Automatizar el servidor

Si deseas evitar los pasos manuales cada vez que inicias el sistema,
puedes registrar el script `start.sh` como un servicio `systemd` (Linux).

1. Crea el archivo `/etc/systemd/system/fennec.service` con el siguiente contenido:

```ini
[Unit]
Description=Servidor Fennec AI
After=network.target

[Service]
User=<TU_USUARIO>
WorkingDirectory=/ruta/a/FENNECK-BACK
ExecStart=/ruta/a/FENNECK-BACK/start.sh
Restart=always

[Install]
WantedBy=multi-user.target
```

Reemplaza `<TU_USUARIO>` y las rutas seg√∫n tu entorno.
Luego ejecuta:

```bash
sudo systemctl daemon-reload
sudo systemctl enable --now fennec.service
```

El servidor quedar√° activo en segundo plano y podr√°s abrir
`fennec_assistant.html` directamente cuando lo necesites.
